{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiUM1REVUZ3vqzkEQjH3SI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youkiti/ARE/blob/main/Data_extraction_from_fulltext_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is a code to simplify the full-text review of a PDF file using OpenAI's GPT-4 API.\n",
        "\n",
        "##Inspiration: https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1689?af=R\n",
        "##Requirements:\n",
        "\n",
        "*   pdf files in Google drive\n",
        "*   OpenAI API key\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RcQlAwPlCp1I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf44lKjCA0eo",
        "outputId": "83174ac7-e7a5-4459-b112-07ee4ba7b2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai pypdf2 llmx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNKJQqq1BG7o",
        "outputId": "d747c2c6-78e2-493c-b6a1-2bf8bb42d94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#configuration"
      ],
      "metadata": {
        "id": "Xd4XzzNyGgcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import PyPDF2\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "#OPEN AI key\n",
        "API_KEY = userdata.get('opanai_API_key')\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "#If you use Azure\n",
        "\"\"\"\n",
        "#key\n",
        "API_KEY = userdata.get('Azure_API_key')\n",
        "RESOURCE_ENDPOINT = userdata.get('RESOURCE_ENDPOINT')\n",
        "\n",
        "#client\n",
        "client = AzureOpenAI(\n",
        "    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning\n",
        "    api_version=\"2023-12-01-preview\",\n",
        "    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource\n",
        "    azure_endpoint=RESOURCE_ENDPOINT,\n",
        "    api_key=API_KEY\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#deploy names\n",
        "deployment_ids = [\"gpt-4-1106-preview\",\"gpt-3.5-turbo-1106\",\"text-embedding-ada-002\"]"
      ],
      "metadata": {
        "id": "UE_BOOcOBIAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data preparation"
      ],
      "metadata": {
        "id": "zKNHM2eeGjFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"YOUR OWN Google Drive PATH, NOT the URL\"\n",
        "os.chdir(folder_path)\n",
        "pdf_files = glob.glob(os.path.join(folder_path, '*.pdf'))"
      ],
      "metadata": {
        "id": "jyLW_eAmGpCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"the number of pdf files:{len(pdf_files)}\")"
      ],
      "metadata": {
        "id": "Yo1YxkNE184_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract text\n",
        "def pdf_extract(pdf_file):\n",
        "  data = []\n",
        "  with open(pdf_file, 'rb') as file:\n",
        "      reader = PyPDF2.PdfReader(file)\n",
        "      # concatenate\n",
        "      text = ''\n",
        "      for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "K6sOW174G_BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process of GPT"
      ],
      "metadata": {
        "id": "OZr3LfJiGlwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To modify the function to extract specific information from a PDF, you should adjust it according to your needs. Ensure that the modifications align with the function calling and settings you plan to use.\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are a systematic reviewer. Please extract the key features from the user inputted research article.\n",
        "Specifically, user need information about the title of the article, publication year, the names of authors,  the country where the research was conducted, the study design, and the outcomes.\n",
        "Please extract the concept of the outcomes as defined in the method, and the actual result values separatedly.\n",
        "Please extract the conclusion of the discussion.\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NETZ_jLBCZ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask GPT to write the JSON of function calling\n",
        "\n",
        "system_for_function = \"\"\"\n",
        "Write a JSON structure for a function specification that includes the name of the function, a description, and detailed parameters based on the requirements listed in the system message. Each parameter should have a type and a brief description. Format the JSON as you would for API documentation.\n",
        "\n",
        "#example of a system message and JSON structure\n",
        "system_message = You are a systematic reviewer. Please extract the key features from the user inputted research article. User need information about the title of the article, publication year.\n",
        "\n",
        "functions=[\n",
        "    {\n",
        "        \"name\":\"data_extraction\",\n",
        "        \"description\":\"characteristics of the study\",\n",
        "        \"parameters\":{\n",
        "            \"type\":\"object\",\n",
        "            \"properties\":{\n",
        "                \"title\":{\n",
        "                    \"type\":\"string\",\n",
        "                    \"description\":\"the title of the research article\"\n",
        "                },\n",
        "                \"publication year\":{\n",
        "                    \"type\":\"string\",\n",
        "                    \"description\":\"the publication year of the research article\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "functions = [\n",
        "    {\n",
        "        \"name\":\"json_output\",\n",
        "        \"description\":\" a JSON structure for a function specification\",\n",
        "        \"parameters\":{\n",
        "            \"type\":\"object\",\n",
        "            \"properties\":{\n",
        "                \"json\":{\n",
        "                    \"type\":\"string\",\n",
        "                    \"description\":\"JSON\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "res = client.chat.completions.create(\n",
        "    model=deployment_ids[0],\n",
        "    messages=[\n",
        "        {\"role\":\"system\",\n",
        "        \"content\":system_for_function},\n",
        "        {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": system_message\n",
        "        }],\n",
        "    functions = functions,\n",
        "    function_call = \"auto\",\n",
        "    temperature = 0\n",
        "  )\n",
        "\n",
        "res = res.model_dump_json()\n",
        "res = json.loads(res)\n",
        "response = res[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"]\n",
        "functions = [json.loads(response)]\n",
        "\n",
        "#check the outputs\n",
        "if 'functions' in functions[0]:\n",
        "  functions = functions[0]['functions']\n",
        "else:\n",
        "  functions = functions\n",
        "\n",
        "print(functions)\n"
      ],
      "metadata": {
        "id": "oLMI65ofeW8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "↑Even if you use function calling, the output will not be stable, so please visually check that the format is correct."
      ],
      "metadata": {
        "id": "bc4YPMY7aB_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GPT_extract(text):\n",
        "  res = client.chat.completions.create(\n",
        "    model=deployment_ids[0],\n",
        "    messages=[\n",
        "        {\"role\":\"system\",\n",
        "        \"content\":system_message},\n",
        "        {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": text\n",
        "        }],\n",
        "    functions=functions,\n",
        "    function_call = \"auto\",\n",
        "    temperature = 0\n",
        "  )\n",
        "  response_json = res.model_dump_json()\n",
        "  response_json = json.loads(response_json)\n",
        "  response_json = response_json[\"choices\"][0][\"message\"][\"function_call\"]\n",
        "  return response_json"
      ],
      "metadata": {
        "id": "G1NRM6xZJrq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "for pdf_file in tqdm(pdf_files):\n",
        "  text = pdf_extract(pdf_file)\n",
        "  response_json = GPT_extract(text)\n",
        "  arguments_str = response_json['arguments']\n",
        "  arguments_json = json.loads(arguments_str)\n",
        "  df_pdf = pd.DataFrame([arguments_json])\n",
        "  df = pd.concat([df, df_pdf])"
      ],
      "metadata": {
        "id": "HWP7NAeVFQtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the pdf file names\n",
        "pdf_filenames = [os.path.basename(pdf_path) for pdf_path in pdf_files]\n",
        "df[\"pdf_name\"] = pdf_filenames"
      ],
      "metadata": {
        "id": "GDf8pMYAMHgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "mo5XnpDU2IB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save\n",
        "df.to_csv('data_extraction.csv',index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "3cP6mA2gISXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
